{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7erE_HZw88VE",
        "outputId": "4fd77ff2-ec55-4433-d937-168eb8225141"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langgraph in /usr/local/lib/python3.12/dist-packages (1.0.2)\n",
            "Requirement already satisfied: langchain-core>=0.1 in /usr/local/lib/python3.12/dist-packages (from langgraph) (1.0.3)\n",
            "Requirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from langgraph) (3.0.1)\n",
            "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in /usr/local/lib/python3.12/dist-packages (from langgraph) (1.0.2)\n",
            "Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.2 in /usr/local/lib/python3.12/dist-packages (from langgraph) (0.2.9)\n",
            "Requirement already satisfied: pydantic>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langgraph) (2.11.10)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph) (3.6.0)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (0.4.38)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (25.0)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (6.0.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (8.5.0)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (4.15.0)\n",
            "Requirement already satisfied: ormsgpack>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph) (1.12.0)\n",
            "Requirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (3.11.4)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langgraph) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langgraph) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langgraph) (0.4.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (4.11.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core>=0.1->langgraph) (3.0.0)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (1.0.0)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (2.32.4)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (0.25.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (2.5.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (1.3.1)\n",
            "python: 3.12.12 (main, Oct 10 2025, 08:52:57) [GCC 11.4.0]\n",
            "langgraph: unknown\n",
            "langchain: 1.0.1\n"
          ]
        }
      ],
      "source": [
        "# Cell 1 - Install / upgrade LangGraph + deps (best-practice pinned install)\n",
        "# If you want the absolute latest, you can remove the ==1.0.2 pin, but pinning avoids surprises.\n",
        "!pip install -qU langchain python-dotenv graphviz\n",
        "!pip install -U langgraph\n",
        "\n",
        "# Verify versions programmatically\n",
        "import importlib, pkgutil, sys\n",
        "import langgraph, langchain\n",
        "from packaging import version\n",
        "\n",
        "print(\"python:\", sys.version.splitlines()[0])\n",
        "print(\"langchain:\", getattr(langchain, \"__version__\", \"unknown\"))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip show langgraph"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J_Bo6m8i--YS",
        "outputId": "b451a5e7-3f5e-4143-9a20-4e4fb8807525"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: langgraph\n",
            "Version: 1.0.2\n",
            "Summary: Building stateful, multi-actor applications with LLMs\n",
            "Home-page: \n",
            "Author: \n",
            "Author-email: \n",
            "License: \n",
            "Location: /usr/local/lib/python3.12/dist-packages\n",
            "Requires: langchain-core, langgraph-checkpoint, langgraph-prebuilt, langgraph-sdk, pydantic, xxhash\n",
            "Required-by: langchain\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "GOOGLE_API_KEY = userdata.get(\"GOOGLE_API_KEY\")\n"
      ],
      "metadata": {
        "id": "2mKnhNBj9ASc"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2 - Try correct imports; helper to re-install if import fails\n",
        "try:\n",
        "    # Correct modern entrypoints\n",
        "    from langgraph.graph import StateGraph, START, END, add_messages\n",
        "    print(\"✅ Imported StateGraph and constants successfully.\")\n",
        "except Exception as e:\n",
        "    print(\"❌ Import failed:\", e)\n",
        "    print(\"Attempting to upgrade langgraph to the latest version and re-import...\")\n",
        "    !pip install -qU langgraph\n",
        "    # retry import\n",
        "    from importlib import reload\n",
        "    import langgraph as _lg\n",
        "    reload(_lg)\n",
        "    from langgraph.graph import StateGraph, START, END, add_messages\n",
        "    print(\"✅ Re-imported after upgrade.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YYMyDah49RNb",
        "outputId": "9d36f1b7-0007-4cfe-eae3-5efe7e95fbf2"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Imported StateGraph and constants successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 3 - LLM selector (Gemini or OpenAI). Put keys in environment (Colab: use %env or set via os.environ)\n",
        "from google.colab import userdata\n",
        "GOOGLE_API_KEY = userdata.get(\"GOOGLE_API_KEY\")\n",
        "\n",
        "if not (GOOGLE_API_KEY):\n",
        "    print(\"⚠️ No LLM API key detected. You can still run the graph in a 'mock' mode below.\")\n",
        "else:\n",
        "    print(\"Detected LLM keys:\", \"Google\" if GOOGLE_API_KEY else \"\")\n",
        "\n",
        "# LLM wrapper function (keeps notebook LLM-agnostic)\n",
        "def get_llm():\n",
        "    if GOOGLE_API_KEY:\n",
        "        from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "        return ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", google_api_key=GOOGLE_API_KEY)\n",
        "    else:\n",
        "        class MockLLM:\n",
        "            def invoke(self, prompt):\n",
        "                return type(\"R\", (), {\"content\": f\"[MOCK OUTPUT: {prompt[:60]}...]\"})\n",
        "        return MockLLM()\n",
        "\n",
        "llm = get_llm()\n",
        "print(\"✅ Using:\", type(llm).__name__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z-xkOzzj9jjY",
        "outputId": "a9021d7e-e5eb-4fbb-8647-552cf1699e77"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detected LLM keys: Google\n",
            "✅ Using: ChatGoogleGenerativeAI\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing_extensions import TypedDict\n",
        "\n",
        "class State(TypedDict):\n",
        "    text: str\n",
        "    summary: str\n",
        "    sentiment: str\n",
        "\n",
        "def call_llm(prompt: str):\n",
        "    \"\"\"Unified LLM call safe for both OpenAI and Gemini adapters.\"\"\"\n",
        "    if hasattr(llm, \"invoke\"):\n",
        "        try:\n",
        "            return llm.invoke(prompt).content\n",
        "        except Exception as e:\n",
        "            # Gemini client errors often arise from internal keyword differences\n",
        "            print(\"⚠️ invoke() failed:\", e)\n",
        "    if hasattr(llm, \"generate\"):\n",
        "        try:\n",
        "            return llm.generate([prompt]).generations[0][0].text\n",
        "        except Exception as e:\n",
        "            print(\"⚠️ generate() failed:\", e)\n",
        "    # fallback for mock mode\n",
        "    return f\"[MOCK OUTPUT: {prompt[:60]}...]\"\n",
        "\n",
        "def node_summarize(state: State):\n",
        "    prompt = f\"Summarize this text in one concise sentence:\\n\\n{state['text']}\"\n",
        "    state[\"summary\"] = call_llm(prompt)\n",
        "    return state\n",
        "\n",
        "def node_sentiment(state: State):\n",
        "    prompt = f\"Determine sentiment (Positive/Negative/Neutral):\\n\\n{state['text']}\"\n",
        "    state[\"sentiment\"] = call_llm(prompt)\n",
        "    return state\n",
        "\n",
        "print(\"✅ Node functions updated for modern LLM wrappers.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uv3OjnUv_iKR",
        "outputId": "84e126f0-86f0-450d-c2dc-20f95870def5"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Node functions updated for modern LLM wrappers.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 5 - Build and compile a StateGraph\n",
        "builder = StateGraph(State)\n",
        "\n",
        "# Add nodes and set entry/finish (modern pattern uses set_entry_point / set_finish_point)\n",
        "builder.add_node(\"summarize\", node_summarize)\n",
        "builder.add_node(\"sentiment\", node_sentiment)\n",
        "\n",
        "builder.set_entry_point(\"summarize\")\n",
        "builder.set_finish_point(\"sentiment\")\n",
        "\n",
        "# connect summarize -> sentiment\n",
        "builder.add_edge(\"summarize\", \"sentiment\")\n",
        "\n",
        "graph = builder.compile()\n",
        "print(\"✅ Graph compiled. Entry:\", \"summarize\", \"Finish:\", \"sentiment\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NiF3FSwt_phQ",
        "outputId": "a0b5a6e0-b7f7-49ef-a361-7074661764a4"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Graph compiled. Entry: summarize Finish: sentiment\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.graph import StateGraph, START, END\n",
        "\n",
        "builder = StateGraph(State)\n",
        "builder.add_node(\"summarize\", node_summarize)\n",
        "builder.add_node(\"sentiment\", node_sentiment)\n",
        "builder.set_entry_point(\"summarize\")\n",
        "builder.set_finish_point(\"sentiment\")\n",
        "builder.add_edge(\"summarize\", \"sentiment\")\n",
        "\n",
        "graph = builder.compile()\n",
        "\n",
        "result = graph.invoke({\n",
        "    \"text\": \"LangGraph is a modern framework for building stateful AI workflows.\",\n",
        "    \"summary\": \"\",\n",
        "    \"sentiment\": \"\"\n",
        "})\n",
        "\n",
        "import json\n",
        "print(json.dumps(result, indent=2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P781PvjI_rZn",
        "outputId": "154a208c-1d16-41d2-ac92-45c5a5ee5694"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"text\": \"LangGraph is a modern framework for building stateful AI workflows.\",\n",
            "  \"summary\": \"LangGraph is a modern framework for building stateful AI workflows.\",\n",
            "  \"sentiment\": \"Positive\"\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 7 - Conditional branching example\n",
        "def praise_node(state: State):\n",
        "    print(\"PRAISE:\", state[\"summary\"])\n",
        "    return state\n",
        "\n",
        "def critique_node(state: State):\n",
        "    print(\"CRITIQUE:\", state[\"summary\"])\n",
        "    return state\n",
        "\n",
        "builder2 = StateGraph(State)\n",
        "builder2.add_node(\"summarize\", node_summarize)\n",
        "builder2.add_node(\"sentiment\", node_sentiment)\n",
        "builder2.add_node(\"praise\", praise_node)\n",
        "builder2.add_node(\"critique\", critique_node)\n",
        "\n",
        "builder2.set_entry_point(\"summarize\")\n",
        "builder2.set_finish_point(\"praise\")  # we will route to praise or critique dynamically\n",
        "\n",
        "builder2.add_edge(\"summarize\", \"sentiment\")\n",
        "\n",
        "# routing function\n",
        "def choose_route(state: State):\n",
        "    s = (state.get(\"sentiment\",\"\") or \"\").lower()\n",
        "    if \"positive\" in s:\n",
        "        return \"praise\"\n",
        "    else:\n",
        "        return \"critique\"\n",
        "\n",
        "# add conditional edges using current API\n",
        "builder2.add_conditional_edges(\"sentiment\", choose_route, {\"praise\":\"praise\", \"critique\":\"critique\"})\n",
        "builder2.add_edge(\"praise\", END)\n",
        "builder2.add_edge(\"critique\", END)\n",
        "\n",
        "g2 = builder2.compile()\n",
        "print(\"Compiled conditional graph.\")\n",
        "g2.invoke({\"text\":\"I love this API! It's great.\",\"summary\":\"\",\"sentiment\":\"\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u8f0cEev_tb_",
        "outputId": "df7c3538-e347-4a35-b8ff-4dd077883835"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Compiled conditional graph.\n",
            "PRAISE: The API is highly praised.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'text': \"I love this API! It's great.\",\n",
              " 'summary': 'The API is highly praised.',\n",
              " 'sentiment': 'Sentiment: **Positive**'}"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U langgraph"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vn5q_FH_EGwn",
        "outputId": "4a61801f-9453-4088-ce25-49ba06bfe8a9"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langgraph in /usr/local/lib/python3.12/dist-packages (1.0.2)\n",
            "Requirement already satisfied: langchain-core>=0.1 in /usr/local/lib/python3.12/dist-packages (from langgraph) (1.0.3)\n",
            "Requirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from langgraph) (3.0.1)\n",
            "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in /usr/local/lib/python3.12/dist-packages (from langgraph) (1.0.2)\n",
            "Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.2 in /usr/local/lib/python3.12/dist-packages (from langgraph) (0.2.9)\n",
            "Requirement already satisfied: pydantic>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langgraph) (2.11.10)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph) (3.6.0)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (0.4.38)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (25.0)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (6.0.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (8.5.0)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (4.15.0)\n",
            "Requirement already satisfied: ormsgpack>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph) (1.12.0)\n",
            "Requirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (3.11.4)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langgraph) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langgraph) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langgraph) (0.4.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (4.11.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core>=0.1->langgraph) (3.0.0)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (1.0.0)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (2.32.4)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (0.25.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (2.5.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (1.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image, display\n",
        "import tempfile, os, subprocess\n",
        "\n",
        "app = builder.compile()\n",
        "\n",
        "try:\n",
        "    # Try to get Mermaid syntax\n",
        "    dot_or_mermaid = app.get_graph().draw_mermaid()\n",
        "except Exception as e:\n",
        "    print(\"❗ Could not call draw_mermaid():\", e)\n",
        "    try:\n",
        "        # Fallback to older PNG bytes\n",
        "        img_bytes = app.get_graph().draw_mermaid_png()\n",
        "        display(Image(img_bytes))\n",
        "        dot_or_mermaid = None\n",
        "    except Exception as e2:\n",
        "        print(\"❗ Could not call draw_mermaid_png():\", e2)\n",
        "        dot_or_mermaid = None\n",
        "\n",
        "if isinstance(dot_or_mermaid, str):\n",
        "    # we have Mermaid source\n",
        "    print(\"Mermaid code (paste into mermaid.live):\")\n",
        "    print(dot_or_mermaid)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ExKT4ENqCs6Q",
        "outputId": "400530a8-d8fc-4bde-d42b-97b0f85d4c18"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mermaid code (paste into mermaid.live):\n",
            "---\n",
            "config:\n",
            "  flowchart:\n",
            "    curve: linear\n",
            "---\n",
            "graph TD;\n",
            "\t__start__([<p>__start__</p>]):::first\n",
            "\tsummarize(summarize)\n",
            "\tsentiment(sentiment)\n",
            "\t__end__([<p>__end__</p>]):::last\n",
            "\t__start__ --> summarize;\n",
            "\tsummarize --> sentiment;\n",
            "\tsentiment --> __end__;\n",
            "\tclassDef default fill:#f2f0ff,line-height:1.2\n",
            "\tclassDef first fill-opacity:0\n",
            "\tclassDef last fill:#bfb6fc\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ieD_WzgNEdsn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}