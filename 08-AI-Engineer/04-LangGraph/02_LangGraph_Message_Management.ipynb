{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vgz2tk_DFsVU",
        "outputId": "986fc885-1437-4f9e-e9ce-10a80c8a77b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/156.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m \u001b[32m153.6/156.8 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m156.8/156.8 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m469.9/469.9 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m81.9/81.9 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m46.2/46.2 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.8/56.8 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m208.3/208.3 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "langchain 0.3.27 requires langchain-core<1.0.0,>=0.3.72, but you have langchain-core 1.0.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m463.4/463.4 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "langchain 0.3.27 requires langchain-core<1.0.0,>=0.3.72, but you have langchain-core 1.0.3 which is incompatible.\n",
            "gradio 5.49.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -qU langgraph langchain_core langchain-openai\n",
        "!pip install -qU pydantic"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Annotated, List\n",
        "from langgraph.graph import StateGraph, END\n",
        "from langgraph.checkpoint.memory import InMemorySaver\n",
        "from langchain_core.messages import HumanMessage, AIMessage, BaseMessage\n",
        "from langgraph.graph.message import MessagesState\n",
        "from langchain_core.messages.modifier import RemoveMessage\n",
        "from langchain_core.runnables import RunnableLambda\n",
        "from langgraph.graph import StateGraph\n",
        "from langgraph.graph.message import add_messages\n",
        "import random"
      ],
      "metadata": {
        "id": "LuIu_ZJBF2Eq"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import TypedDict\n",
        "\n",
        "# Define annotated state for messages\n",
        "class ChatState(TypedDict):\n",
        "    # Modern LangGraph (2025): reducers are defined via annotation\n",
        "    messages: Annotated[List[BaseMessage], add_messages]"
      ],
      "metadata": {
        "id": "XKxVbd7sF7ML"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example reducer that appends new messages to existing history\n",
        "def append_reducer(existing: List, new: List):\n",
        "    return existing + new\n",
        "\n",
        "# Example reducer that trims the message history to last N messages\n",
        "def trim_reducer(existing: List, new: List, max_messages=5):\n",
        "    combined = existing + new\n",
        "    if len(combined) > max_messages:\n",
        "        combined = combined[-max_messages:]\n",
        "    return combined"
      ],
      "metadata": {
        "id": "dd55i9zLHjQn"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def user_node(state: ChatState):\n",
        "    \"\"\"Simulate user sending a message.\"\"\"\n",
        "    msg = HumanMessage(content=random.choice([\n",
        "        \"Hello!\", \"How are you?\", \"Tell me something cool.\", \"Let's talk about AI.\"\n",
        "    ]))\n",
        "    return {\"messages\": [msg]}\n",
        "\n",
        "def ai_node(state: ChatState):\n",
        "    \"\"\"Simulate AI responding.\"\"\"\n",
        "    last_msg = state[\"messages\"][-1].content if state[\"messages\"] else \"Hi!\"\n",
        "    response = AIMessage(content=f\"AI Response to: {last_msg}\")\n",
        "    return {\"messages\": [response]}\n"
      ],
      "metadata": {
        "id": "UUg7gKgOHk2m"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# âœ… Cell 6 â€” Build Graph with Entry Point (2025 syntax)\n",
        "\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langgraph.checkpoint.memory import InMemorySaver\n",
        "\n",
        "# Initialize in-memory checkpointer\n",
        "checkpointer = InMemorySaver()\n",
        "\n",
        "# Create graph for our ChatState\n",
        "graph = StateGraph(ChatState)\n",
        "\n",
        "# Add nodes\n",
        "graph.add_node(\"user\", user_node)\n",
        "graph.add_node(\"ai\", ai_node)\n",
        "\n",
        "# âœ… Define edges including entrypoint\n",
        "graph.add_edge(START, \"user\")   # Entry point (new requirement)\n",
        "graph.add_edge(\"user\", \"ai\")\n",
        "graph.add_edge(\"ai\", END)\n",
        "\n",
        "# âœ… Compile graph (reducers already inferred from Annotated state)\n",
        "app = graph.compile(checkpointer=checkpointer)\n",
        "\n",
        "print(\"âœ… LangGraph compiled successfully (modern entrypoint & reducer syntax).\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HWFI6hEFHnPm",
        "outputId": "7dff6a90-15e5-4bc4-bf29-918ca75191dd"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… LangGraph compiled successfully (modern entrypoint & reducer syntax).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# âœ… Cell 7 â€” Run the Graph and View State\n",
        "\n",
        "# Initial state â€” empty conversation\n",
        "initial_state = {\"messages\": []}\n",
        "\n",
        "# âœ… Each invocation must include a thread_id for the checkpointer\n",
        "config = {\"configurable\": {\"thread_id\": \"demo-thread\"}}\n",
        "\n",
        "# Run one full user â†’ AI turn\n",
        "final_state = app.invoke(initial_state, config=config)\n",
        "\n",
        "# Display conversation history\n",
        "print(\"ğŸ—¨ï¸ Conversation Messages:\")\n",
        "for msg in final_state[\"messages\"]:\n",
        "    print(f\"{msg.type.upper()}: {msg.content}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "beC7r5flHpLO",
        "outputId": "98cd1beb-93a3-4baf-a7fa-3592ded3f59b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ—¨ï¸ Conversation Messages:\n",
            "HUMAN: How are you?\n",
            "AI: AI Response to: How are you?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# âœ… Cell 8 â€” Demonstrate Removing Messages (modern API)\n",
        "\n",
        "from langchain_core.messages.modifier import RemoveMessage\n",
        "from langchain_core.messages import BaseMessage\n",
        "\n",
        "def remove_ai_messages_node(state: ChatState):\n",
        "    \"\"\"\n",
        "    Node that removes all AI messages from the conversation.\n",
        "    Demonstrates how RemoveMessage works with add_messages reducer.\n",
        "    \"\"\"\n",
        "    msgs = state[\"messages\"]\n",
        "    # Collect RemoveMessage instructions for every AI message\n",
        "    removals = [RemoveMessage(id=m.id) for m in msgs if m.type == \"ai\"]\n",
        "    return {\"messages\": removals}\n",
        "\n",
        "\n",
        "# Add the node to the graph for demonstration\n",
        "graph = StateGraph(ChatState)\n",
        "graph.add_node(\"user\", user_node)\n",
        "graph.add_node(\"ai\", ai_node)\n",
        "graph.add_node(\"remove_ai\", remove_ai_messages_node)\n",
        "\n",
        "# Define flow: START â†’ user â†’ ai â†’ remove_ai â†’ END\n",
        "graph.add_edge(START, \"user\")\n",
        "graph.add_edge(\"user\", \"ai\")\n",
        "graph.add_edge(\"ai\", \"remove_ai\")\n",
        "graph.add_edge(\"remove_ai\", END)\n",
        "\n",
        "# Compile with same checkpointer\n",
        "app_remove = graph.compile(checkpointer=InMemorySaver())\n",
        "\n",
        "# Run through the updated flow\n",
        "config = {\"configurable\": {\"thread_id\": \"remove-demo\"}}\n",
        "final_state = app_remove.invoke({\"messages\": []}, config=config)\n",
        "\n",
        "print(\"ğŸ§½ After Removing AI Messages:\")\n",
        "for msg in final_state[\"messages\"]:\n",
        "    print(f\"{msg.type.upper()}: {msg.content}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HTe0yDt9IxCW",
        "outputId": "51118a57-fa0b-482c-ccef-de992155ebca"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ§½ After Removing AI Messages:\n",
            "HUMAN: Tell me something cool.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# âœ… Cell 9 â€” Trimming & Summarizing Messages (2025 syntax)\n",
        "\n",
        "from langchain_core.messages import AIMessage, HumanMessage\n",
        "\n",
        "def summarize_old_messages(messages):\n",
        "    \"\"\"\n",
        "    Simple summarization stub for demonstration.\n",
        "    In production, you'd replace this with an LLM summarizer or LangChain Runnable.\n",
        "    \"\"\"\n",
        "    # Concatenate content of all messages into a short summary\n",
        "    combined_text = \" | \".join(m.content for m in messages)\n",
        "    return f\"Summary: {combined_text[:120]}...\"\n",
        "\n",
        "\n",
        "def trim_and_summarize_node(state: ChatState, max_messages=4):\n",
        "    \"\"\"\n",
        "    Trims long conversation histories and replaces removed parts with a summary.\n",
        "    Works with the add_messages reducer.\n",
        "    \"\"\"\n",
        "    msgs = state[\"messages\"]\n",
        "\n",
        "    # If conversation is short enough, no action needed\n",
        "    if len(msgs) <= max_messages:\n",
        "        return {\"messages\": []}\n",
        "\n",
        "    # Messages to summarize (all but the last N)\n",
        "    old_msgs = msgs[:-max_messages]\n",
        "    recent_msgs = msgs[-max_messages:]\n",
        "\n",
        "    # Create a new summary message\n",
        "    summary = AIMessage(content=summarize_old_messages(old_msgs))\n",
        "\n",
        "    # Return a replacement update:\n",
        "    #  - Remove old messages\n",
        "    #  - Add one summary message\n",
        "    from langchain_core.messages.modifier import RemoveMessage\n",
        "    removals = [RemoveMessage(id=m.id) for m in old_msgs]\n",
        "\n",
        "    return {\"messages\": removals + [summary]}\n",
        "\n",
        "\n",
        "# Build a small demo graph that includes the summarizer node\n",
        "graph = StateGraph(ChatState)\n",
        "graph.add_node(\"user\", user_node)\n",
        "graph.add_node(\"ai\", ai_node)\n",
        "graph.add_node(\"trim_summarize\", trim_and_summarize_node)\n",
        "\n",
        "# Flow: START â†’ user â†’ ai â†’ trim_summarize â†’ END\n",
        "graph.add_edge(START, \"user\")\n",
        "graph.add_edge(\"user\", \"ai\")\n",
        "graph.add_edge(\"ai\", \"trim_summarize\")\n",
        "graph.add_edge(\"trim_summarize\", END)\n",
        "\n",
        "# Compile the graph\n",
        "app_trim = graph.compile(checkpointer=InMemorySaver())\n",
        "\n",
        "# Run multiple turns to see trimming kick in\n",
        "config = {\"configurable\": {\"thread_id\": \"summary-demo\"}}\n",
        "state = {\"messages\": []}\n",
        "\n",
        "for _ in range(6):  # simulate 6 turns\n",
        "    state = app_trim.invoke(state, config=config)\n",
        "\n",
        "print(\"ğŸª¶ After Trimming & Summarization:\")\n",
        "for msg in state[\"messages\"]:\n",
        "    print(f\"{msg.type.upper()}: {msg.content}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ZTJ5Iw4JGke",
        "outputId": "6c1d55bd-1df5-4f88-c110-b23c7e0f1f0b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸª¶ After Trimming & Summarization:\n",
            "AI: AI Response to: How are you?\n",
            "AI: Summary: AI Response to: Tell me something cool. | Summary: Hello! | AI Response to: Hello!... | Hello!...\n",
            "HUMAN: Tell me something cool.\n",
            "AI: AI Response to: Tell me something cool.\n",
            "AI: Summary: AI Response to: Hello! | Summary: How are you? | AI Response to: How are you? | Tell me something cool.... | How are you...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# âœ… Cell 10 â€” Full Conversational Simulation (Modern LangGraph 2025)\n",
        "\n",
        "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage\n",
        "from langchain_core.messages.modifier import RemoveMessage\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langgraph.checkpoint.memory import InMemorySaver\n",
        "from typing import Annotated, List\n",
        "from langgraph.graph.message import add_messages\n",
        "\n",
        "# --- State Definition ---\n",
        "class ChatState(TypedDict):\n",
        "    messages: Annotated[List[BaseMessage], add_messages]\n",
        "\n",
        "# --- Core Nodes ---\n",
        "def user_node(state: ChatState):\n",
        "    \"\"\"Simulate user sending random messages.\"\"\"\n",
        "    import random\n",
        "    msg = HumanMessage(content=random.choice([\n",
        "        \"Hey there!\", \"What's new in AI?\", \"Tell me something interesting.\",\n",
        "        \"Can you summarize our chat?\", \"I'm learning LangGraph!\"\n",
        "    ]))\n",
        "    return {\"messages\": [msg]}\n",
        "\n",
        "def ai_node(state: ChatState):\n",
        "    \"\"\"AI echoes the latest user message.\"\"\"\n",
        "    last_msg = state[\"messages\"][-1].content if state[\"messages\"] else \"Hi!\"\n",
        "    response = AIMessage(content=f\"AI Response to: {last_msg}\")\n",
        "    return {\"messages\": [response]}\n",
        "\n",
        "def remove_noise_node(state: ChatState):\n",
        "    \"\"\"\n",
        "    Demonstrate removing specific messages.\n",
        "    Example: remove AI messages that contain 'echo' or are too short.\n",
        "    \"\"\"\n",
        "    removals = [\n",
        "        RemoveMessage(id=m.id)\n",
        "        for m in state[\"messages\"]\n",
        "        if m.type == \"ai\" and \"echo\" in m.content.lower()\n",
        "    ]\n",
        "    return {\"messages\": removals}\n",
        "\n",
        "def summarize_old_messages(messages):\n",
        "    \"\"\"Simple summarization placeholder.\"\"\"\n",
        "    joined = \" | \".join(m.content for m in messages)\n",
        "    return f\"Summary: {joined[:120]}...\"\n",
        "\n",
        "def trim_and_summarize_node(state: ChatState, max_messages=5):\n",
        "    \"\"\"Keep only last N messages, summarize the rest.\"\"\"\n",
        "    msgs = state[\"messages\"]\n",
        "    if len(msgs) <= max_messages:\n",
        "        return {\"messages\": []}\n",
        "    old, recent = msgs[:-max_messages], msgs[-max_messages:]\n",
        "    summary = AIMessage(content=summarize_old_messages(old))\n",
        "    removals = [RemoveMessage(id=m.id) for m in old]\n",
        "    return {\"messages\": removals + [summary]}\n",
        "\n",
        "\n",
        "# --- Graph Assembly ---\n",
        "graph = StateGraph(ChatState)\n",
        "graph.add_node(\"user\", user_node)\n",
        "graph.add_node(\"ai\", ai_node)\n",
        "graph.add_node(\"remove_noise\", remove_noise_node)\n",
        "graph.add_node(\"trim_summarize\", trim_and_summarize_node)\n",
        "\n",
        "# Flow: START â†’ user â†’ ai â†’ remove_noise â†’ trim_summarize â†’ END\n",
        "graph.add_edge(START, \"user\")\n",
        "graph.add_edge(\"user\", \"ai\")\n",
        "graph.add_edge(\"ai\", \"remove_noise\")\n",
        "graph.add_edge(\"remove_noise\", \"trim_summarize\")\n",
        "graph.add_edge(\"trim_summarize\", END)\n",
        "\n",
        "# --- Compile ---\n",
        "checkpointer = InMemorySaver()\n",
        "app_full = graph.compile(checkpointer=checkpointer)\n",
        "\n",
        "# --- Run Full Simulation ---\n",
        "config = {\"configurable\": {\"thread_id\": \"final-simulation\"}}\n",
        "state = {\"messages\": []}\n",
        "\n",
        "print(\"ğŸš€ Running full LangGraph chat simulation...\\n\")\n",
        "\n",
        "for i in range(8):  # 8 turns to force trimming + summarization\n",
        "    state = app_full.invoke(state, config=config)\n",
        "\n",
        "print(\"\\nğŸ’¬ Final Conversation State:\")\n",
        "for msg in state[\"messages\"]:\n",
        "    print(f\"{msg.type.upper()}: {msg.content}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HUjnhY71J8E-",
        "outputId": "b500eadf-0565-4eaa-e677-0bb3ff24a195"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸš€ Running full LangGraph chat simulation...\n",
            "\n",
            "\n",
            "ğŸ’¬ Final Conversation State:\n",
            "HUMAN: Hey there!\n",
            "AI: AI Response to: Hey there!\n",
            "AI: Summary: Tell me something interesting. | AI Response to: Tell me something interesting. | Summary: Hey there! | AI Response to: ...\n",
            "HUMAN: Can you summarize our chat?\n",
            "AI: AI Response to: Can you summarize our chat?\n",
            "AI: Summary: Can you summarize our chat? | AI Response to: Can you summarize our chat? | Summary: Can you summarize our chat? | AI Re...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_community"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "GXpAg3HWKg5m",
        "outputId": "6dcf1be2-c5e0-4fc8-8916-aa892a55967c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain_community\n",
            "  Downloading langchain_community-0.4.1-py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (1.0.3)\n",
            "Collecting langchain-classic<2.0.0,>=1.0.0 (from langchain_community)\n",
            "  Downloading langchain_classic-1.0.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.0.44)\n",
            "Collecting requests<3.0.0,>=2.32.5 (from langchain_community)\n",
            "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (6.0.3)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (3.13.1)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (8.5.0)\n",
            "Collecting dataclasses-json<0.7.0,>=0.6.7 (from langchain_community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.11.0)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.1.125 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (0.4.38)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (0.4.3)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.22.0)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain_community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain_community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting langchain-text-splitters<2.0.0,>=1.0.0 (from langchain-classic<2.0.0,>=1.0.0->langchain_community)\n",
            "  Downloading langchain_text_splitters-1.0.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain-classic<2.0.0,>=1.0.0->langchain_community) (2.12.4)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.1->langchain_community) (1.33)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.1->langchain_community) (25.0)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.1->langchain_community) (4.15.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain_community) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain_community) (3.11.4)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain_community) (0.25.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain_community) (1.2.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain_community) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain_community) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain_community) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain_community) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain_community) (2025.10.5)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain_community) (3.2.4)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain_community) (4.11.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain_community) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain_community) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.1->langchain_community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-classic<2.0.0,>=1.0.0->langchain_community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.5 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-classic<2.0.0,>=1.0.0->langchain_community) (2.41.5)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain_community)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain_community) (1.3.1)\n",
            "Downloading langchain_community-0.4.1-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading langchain_classic-1.0.0-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m38.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_text_splitters-1.0.0-py3-none-any.whl (33 kB)\n",
            "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Installing collected packages: requests, mypy-extensions, marshmallow, typing-inspect, dataclasses-json, langchain-text-splitters, langchain-classic, langchain_community\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.4\n",
            "    Uninstalling requests-2.32.4:\n",
            "      Successfully uninstalled requests-2.32.4\n",
            "  Attempting uninstall: langchain-text-splitters\n",
            "    Found existing installation: langchain-text-splitters 0.3.11\n",
            "    Uninstalling langchain-text-splitters-0.3.11:\n",
            "      Successfully uninstalled langchain-text-splitters-0.3.11\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\n",
            "langchain 0.3.27 requires langchain-core<1.0.0,>=0.3.72, but you have langchain-core 1.0.3 which is incompatible.\n",
            "langchain 0.3.27 requires langchain-text-splitters<1.0.0,>=0.3.9, but you have langchain-text-splitters 1.0.0 which is incompatible.\n",
            "gradio 5.49.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed dataclasses-json-0.6.7 langchain-classic-1.0.0 langchain-text-splitters-1.0.0 langchain_community-0.4.1 marshmallow-3.26.1 mypy-extensions-1.1.0 requests-2.32.5 typing-inspect-0.9.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "requests"
                ]
              },
              "id": "8f2b18f3c5714898acddf344af0f4b71"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install latest langchain-openai\n",
        "!pip install -U langchain-openai\n",
        "\n",
        "# Correct import\n",
        "from langchain_openai import ChatOpenAI"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HoiXw2ZqLXKH",
        "outputId": "18e28f0e-cb04-4584-f33c-ec5cfbc2271f"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain-openai in /usr/local/lib/python3.12/dist-packages (1.0.2)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=1.0.2 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (1.0.3)\n",
            "Requirement already satisfied: openai<3.0.0,>=1.109.1 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (1.109.1)\n",
            "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (0.12.0)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.2->langchain-openai) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.2->langchain-openai) (0.4.38)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.2->langchain-openai) (25.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.2->langchain-openai) (2.12.4)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.2->langchain-openai) (6.0.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.2->langchain-openai) (8.5.0)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.2->langchain-openai) (4.15.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (4.11.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (0.11.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (4.67.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2.32.5)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai<3.0.0,>=1.109.1->langchain-openai) (3.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai<3.0.0,>=1.109.1->langchain-openai) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai<3.0.0,>=1.109.1->langchain-openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<3.0.0,>=1.109.1->langchain-openai) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.2->langchain-openai) (3.0.0)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.2->langchain-openai) (3.11.4)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.2->langchain-openai) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.2->langchain-openai) (0.25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.0.2->langchain-openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.5 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.0.2->langchain-openai) (2.41.5)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.0.2->langchain-openai) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken<1.0.0,>=0.7.0->langchain-openai) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken<1.0.0,>=0.7.0->langchain-openai) (2.5.0)\n"
          ]
        }
      ]
    }
  ]
}