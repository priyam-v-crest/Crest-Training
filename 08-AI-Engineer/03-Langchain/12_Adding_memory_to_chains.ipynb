{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNo+VeUXqCz9sI8ElGqsSUn"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"iUQUK1wHxnlk","executionInfo":{"status":"ok","timestamp":1760429537351,"user_tz":-330,"elapsed":9096,"user":{"displayName":"Priyam Vyas","userId":"13332163866744380432"}}},"outputs":[],"source":["from google.colab import userdata\n","import os\n","\n","api_key = userdata.get(\"OPENAI_API_KEY\")\n","os.environ[\"OPENAI_API_KEY\"] = api_key\n","\n","os.environ[\"OPENAI_API_BASE\"] = \"https://api.aimlapi.com/v1\""]},{"cell_type":"code","source":["!pip install -q langchain langchain-openai"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KzeFdRcSxq-P","executionInfo":{"status":"ok","timestamp":1760429546171,"user_tz":-330,"elapsed":8807,"user":{"displayName":"Priyam Vyas","userId":"13332163866744380432"}},"outputId":"1918e9a3-6f0b-400a-fbe8-d3ef9ee728bf"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/76.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.0/76.0 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"code","source":["from langchain_openai import ChatOpenAI\n","from langchain.prompts import ChatPromptTemplate\n","from langchain.schema.output_parser import StrOutputParser\n","from langchain.schema.runnable import RunnableSequence, RunnablePassthrough\n","from langchain.memory import ConversationBufferMemory"],"metadata":{"id":"99zNDuYTxvEV","executionInfo":{"status":"ok","timestamp":1760429566226,"user_tz":-330,"elapsed":17293,"user":{"displayName":"Priyam Vyas","userId":"13332163866744380432"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["##Create a Memory Object"],"metadata":{"id":"QHt0mCYzyUtU"}},{"cell_type":"code","source":["# Simple in-memory conversation\n","memory = ConversationBufferMemory(memory_key=\"chat_history\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6yinpj4sxyQM","executionInfo":{"status":"ok","timestamp":1760429568505,"user_tz":-330,"elapsed":41,"user":{"displayName":"Priyam Vyas","userId":"13332163866744380432"}},"outputId":"bdd48385-63eb-415c-a9a4-79af40eba783"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-182861835.py:2: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n","  memory = ConversationBufferMemory(memory_key=\"chat_history\")\n"]}]},{"cell_type":"markdown","source":["##Define Prompt with Memory"],"metadata":{"id":"hF0aQ3bzyZAb"}},{"cell_type":"code","source":["# Prompt template that uses memory\n","prompt = ChatPromptTemplate.from_template(\n","    \"The following is a conversation so far:\\n{chat_history}\\n\"\n","    \"User: {user_input}\\nAI:\"\n",")"],"metadata":{"id":"zZgUHjuQx3BM","executionInfo":{"status":"ok","timestamp":1760429571018,"user_tz":-330,"elapsed":4,"user":{"displayName":"Priyam Vyas","userId":"13332163866744380432"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["##Define the Chain"],"metadata":{"id":"2RxXxk1rycED"}},{"cell_type":"code","source":["model = ChatOpenAI(model=\"gpt-4o-mini\")\n","\n","# Use RunnablePassthrough to attach memory\n","chain = RunnableSequence(\n","    first=RunnablePassthrough(additional_keys=[\"chat_history\", \"user_input\"]),\n","    middle=[prompt, model],\n","    last=StrOutputParser()\n",")"],"metadata":{"id":"9n6HChj6x3o8","executionInfo":{"status":"ok","timestamp":1760429582385,"user_tz":-330,"elapsed":1468,"user":{"displayName":"Priyam Vyas","userId":"13332163866744380432"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["##Run a Conversational Loop"],"metadata":{"id":"4u_jmuMDyf8R"}},{"cell_type":"code","source":["# --- Memory ---\n","memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=False)\n","\n","# --- Prompt ---\n","prompt = ChatPromptTemplate.from_template(\n","    \"The following is a conversation so far:\\n{chat_history}\\n\"\n","    \"User: {user_input}\\nAI:\"\n",")\n","\n","# --- Model ---\n","model = ChatOpenAI(model=\"gpt-4o-mini\")\n","\n","# --- Chain ---\n","chain = RunnableSequence(\n","    first=RunnablePassthrough(additional_keys=[\"chat_history\", \"user_input\"]),\n","    middle=[prompt, model],\n","    last=StrOutputParser()\n",")\n","\n","# --- Multi-turn conversation ---\n","# First turn\n","memory_vars = memory.load_memory_variables({})\n","user_input1 = \"Hello!\"\n","input1 = {\n","    \"user_input\": user_input1,\n","    \"chat_history\": memory_vars[\"chat_history\"]\n","}\n","response1 = chain.invoke(input1)\n","print(\"AI:\", response1)\n","\n","# Save to memory\n","memory.save_context({\"user_input\": user_input1}, {\"output\": response1})\n","\n","# Second turn\n","memory_vars = memory.load_memory_variables({})\n","user_input2 = \"How are you?\"\n","input2 = {\n","    \"user_input\": user_input2,\n","    \"chat_history\": memory_vars[\"chat_history\"]\n","}\n","response2 = chain.invoke(input2)\n","print(\"AI:\", response2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mj-VPZ8Ux6Dk","executionInfo":{"status":"ok","timestamp":1760429653192,"user_tz":-330,"elapsed":2467,"user":{"displayName":"Priyam Vyas","userId":"13332163866744380432"}},"outputId":"ce5dea08-a431-4030-bd4e-6b2d5a6f8e77"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["AI: Hello! How can I assist you today?\n","AI: I'm just a program, but I'm here and ready to help you! How are you?\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"m6p8FReLx7hk"},"execution_count":null,"outputs":[]}]}